{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import pandas as pd\n",
    "from scripts.data_utils import HistopathologyDataModule\n",
    "from scripts.model_utils import BaselineCNN\n",
    "from scripts.config import TEST_DIR, BATCH_SIZE, TARGET_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions_and_submit():\n",
    "    \"\"\"\n",
    "    Main function to load the model, test data, generate predictions,\n",
    "    and save the results to a CSV file for Kaggle submission.\n",
    "    \"\"\"\n",
    "    print(\"Initializing data module...\")\n",
    "    # Instantiate data module and prepare the test dataset\n",
    "    data_module = HistopathologyDataModule(\n",
    "        batch_size=BATCH_SIZE,\n",
    "        target_size=TARGET_SIZE,\n",
    "        test_dir=TEST_DIR\n",
    "    )\n",
    "    data_module.setup(stage=\"test\")\n",
    "\n",
    "    print(\"Loading trained model checkpoint...\")\n",
    "    # Ensure the checkpoint exists before loading\n",
    "    model_path = \"checkpoints/best_model.ckpt\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model checkpoint not found at {model_path}\")\n",
    "\n",
    "    model = BaselineCNN.load_from_checkpoint(model_path)\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    print(\"Generating predictions...\")\n",
    "    # Generate predictions\n",
    "    predictions = []\n",
    "    ids = []\n",
    "    with torch.no_grad():\n",
    "        for batch in data_module.test_dataloader():\n",
    "            images, ids_batch = batch\n",
    "            outputs = model(images)  # Get model predictions\n",
    "            preds = (torch.sigmoid(outputs) > 0.5).float()  # Thresholding for binary classification\n",
    "            predictions.extend(preds.cpu().numpy())\n",
    "            ids.extend(ids_batch)\n",
    "\n",
    "    # Create a DataFrame for the submission file\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": ids,\n",
    "        \"label\": predictions\n",
    "    })\n",
    "\n",
    "    # Save the submission file\n",
    "    submission_file = \"submission.csv\"\n",
    "    submission_df.to_csv(submission_file, index=False)\n",
    "    print(f\"Predictions saved to {submission_file}\")\n",
    "\n",
    "    return submission_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions and save them to submission file\n",
    "submission_file = generate_predictions_and_submit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
