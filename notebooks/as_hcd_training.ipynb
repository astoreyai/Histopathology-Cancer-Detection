{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Notebook - Histopathology Cancer Detection\n",
    "This notebook trains a CNN for binary classification of histopathology images (cancerous vs. non-cancerous).\n",
    "It uses PyTorch Lightning for training and MLflow for logging experiments.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import MLFlowLogger\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from scripts.data_utils import HistopathologyDataModule\n",
    "from scripts.model_utils import BaselineCNN\n",
    "from scripts.config import BATCH_SIZE, LEARNING_RATE, EPOCHS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize MLflow Logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup MLflow Logger\n",
    "mlflow_logger = MLFlowLogger(\n",
    "    experiment_name=\"Histopathology Cancer Detection - Training\",\n",
    "    tracking_uri=\"file:./experiments/mlruns\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize Trainer and Data Module\n",
    "The trainer included early stopping, checkpointing, and MLflow logging. The data module handles loading, augmentation, and batching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define PyTorch Lightning Trainer with callbacks\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=EPOCHS,\n",
    "    logger=mlflow_logger,\n",
    "    gpus=1 if torch.cuda.is_available() else 0,\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_loss\",\n",
    "            dirpath=\"checkpoints/\",\n",
    "            filename=\"best_model\",\n",
    "            save_top_k=1,\n",
    "            mode=\"min\"\n",
    "        ),\n",
    "        EarlyStopping(\n",
    "            monitor=\"val_loss\",\n",
    "            patience=3,\n",
    "            mode=\"min\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_module = HistopathologyDataModule()\n",
    "model = BaselineCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train the model\n",
    "Train the model using the specified configuration and save the best checkpoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(model, data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best model\n",
    "best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "print(f\"Best model saved at: {best_model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Log the Best Model Path to Mlflow and Sync with GitHub\n",
    "Log the best model path to MLflow and ensure GitHub is synced to save experiment results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log the best model path and metrics to MLflow\n",
    "mlflow_logger.experiment.log_param(\n",
    "    run_id=mlflow_logger.run_id,\n",
    "    key=\"best_model_path\",\n",
    "    value=best_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log key metrics to MLflow\n",
    "metrics = trainer.callback_metrics\n",
    "mlflow_logger.experiment.log_metrics(\n",
    "    run_id=mlflow_logger.run_id,\n",
    "    metrics={\n",
    "        \"train_accuracy\": metrics[\"train_accuracy\"].item(),\n",
    "        \"val_accuracy\": metrics[\"val_accuracy\"].item(),\n",
    "        \"val_precision\": metrics[\"val_precision\"].item(),\n",
    "        \"val_recall\": metrics[\"val_recall\"].item(),\n",
    "        \"val_f1\": metrics[\"val_f1\"].item(),\n",
    "        \"val_auc\": metrics[\"val_auc\"].item()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save checkpoint to GitHub if on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git add checkpoints/best_model.ckpt\n",
    "!git commit -m \"Add best model checkpoint\"\n",
    "!git push origin main"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hcd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
